}
plot(
x = Xstar,
y = fmean,
col = "blue",
type = "l",
ylim = c(min(lowerConf), max(upperConf)),
lwd = 2,
sub = subheading,
main = "GP",
ylab = ylab,
xlab = xlab
) +
points(x = X, y = y, col = "green")
legend(
legendPosition,
inset = 0.02,
legend = legendText,
col = legendCols,
pch = c('o', NA, NA, NA),
lty = c(NA, 1, 1, 1),
lwd = 2,
cex = 0.55
)
polygon(
x = c(rev(Xstar), Xstar),
y = c(rev(upperConf), lowerConf),
col = rgb(0, 0, 0, 0.3)
)
if (!sigmaN == 0) {
polygon(
x = c(rev(Xstar), Xstar),
y = c(rev(Y_upperConf), Y_lowerConf),
col = rgb(0, 0, 0.8, 0.3)
)
}
}
#IF NO VARIANCE GIVEN
else {
plot(
x = Xstar,
y = fmean,
col = "blue",
type = "l",
lwd = 2,
sub = subheading,
main = "GP",
ylab = ylab,
xlab = xlab
) +
points(x = X, y = y, col = "green")
legend(
legendPosition,
inset = 0.02,
legend = c("data", "post mean"),
col = c("green", "blue"),
pch = c('o', NA, NA, NA),
lty = c(NA, 1, 1, 1),
lwd = 2,
cex = 0.55
)
}
}
gpParam = posteriorGP(scale(lidarData$Distance), scale(lidarData$LogRatio),
scale(lidarData$Distance), sigmaN/sd(lidarData$LogRatio)^2, kernelWrapper(sigmaF = 1, l = 1))
fmean_unscaled = mean(lidarData$LogRatio) + gpParam$fmean*sd(lidarData$LogRatio)
fvar_unscaled = gpParam$fvar*sd(lidarData$LogRatio)^2
plotGP(fmean_unscaled, fvar_unscaled, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
sigmaN = 0.05
gpParam = posteriorGP(lidarData$Distance, lidarData$LogRatio,
lidarData$Distance, sigmaN, kernelWrapper(sigmaF = 1, l = 1))
plotGP(gpParam$fmean, gpParam$fvar, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
#
sigmaN = 0.05
gpParam = posteriorGP(scale(lidarData$Distance), scale(lidarData$LogRatio),
scale(lidarData$Distance), sigmaN/sd(lidarData$LogRatio)^2, kernelWrapper(sigmaF = 1, l = 1))
fmean_unscaled = mean(lidarData$LogRatio) + gpParam$fmean*sd(lidarData$LogRatio)
fvar_unscaled = gpParam$fvar*sd(lidarData$LogRatio)^2
plotGP(fmean_unscaled, fvar_unscaled, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
sigmaN = 0.05
gpParam = posteriorGP(lidarData$Distance, lidarData$LogRatio,
lidarData$Distance, sigmaN, kernelWrapper(sigmaF = 1, l = 1))
plotGP(gpParam$fmean, gpParam$fvar, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
plotGP(fstar, gpParam$fvar, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
gpParam$fmean
fstar
gpParam$fmean
fstar
gpParam$fmean
fstar
gpParam$fmean
fstar
gpParam$fmean
plotGP(fstar, gpParam$fvar, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
gpParam = posteriorGP(scale(lidarData$Distance), scale(lidarData$LogRatio),
scale(lidarData$Distance), sigmaN/sd(lidarData$LogRatio)^2, kernelWrapper(sigmaF = 1, l = 1))
fmean_unscaled = mean(lidarData$LogRatio) + gpParam$fmean*sd(lidarData$LogRatio)
fvar_unscaled = gpParam$fvar*sd(lidarData$LogRatio)^2
plotGP(fmean_unscaled, fvar_unscaled, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
plotGP(fstar, gpParam$fvar, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
gpParam = posteriorGP(scale(lidarData$Distance), scale(lidarData$LogRatio),
scale(lidarData$Distance), sigmaN/sd(lidarData$LogRatio)^2, kernelWrapper(sigmaF = 1, l = 1))
fmean_unscaled = mean(lidarData$LogRatio) + gpParam$fmean*sd(lidarData$LogRatio)
fvar_unscaled = gpParam$fvar*sd(lidarData$LogRatio)^2
plotGP(fmean_unscaled, fvar_unscaled, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
gpParam = posteriorGP(lidarData$Distance, lidarData$LogRatio,
lidarData$Distance, sigmaN, kernelWrapper(sigmaF = 1, l = 1))
gpParam$fmean
fstar
plotGP(fstar, gpParam$fvar, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
gpParam = posteriorGP(scale(lidarData$Distance), scale(lidarData$LogRatio),
scale(lidarData$Distance), sigmaN/sd(lidarData$LogRatio)^2, kernelWrapper(sigmaF = 1, l = 1))
fmean_unscaled = mean(lidarData$LogRatio) + gpParam$fmean*sd(lidarData$LogRatio)
fvar_unscaled = gpParam$fvar*sd(lidarData$LogRatio)^2
plotGP(fmean_unscaled, fvar_unscaled, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
gpParam = posteriorGP(lidarData$Distance, lidarData$LogRatio,
lidarData$Distance, sigmaN, kernelWrapper(sigmaF = 1, l = 1))
gpParam$fmean
fstar
plotGP(fstar, fvar_unscaled, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
plotGP(fstar, gpParam$fvar, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
plotGP(fstar, fvar_unscaled, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
plotGP(fstar, gpParam$fvar, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
# BETTER ALTERNATIVE
sigmaN = 0.05
gpParam = posteriorGP(scale(lidarData$Distance), scale(lidarData$LogRatio),
scale(lidarData$Distance), sigmaN/sd(lidarData$LogRatio)^2, kernelWrapper(sigmaF = 1, l = 1))
fmean_unscaled = mean(lidarData$LogRatio) + gpParam$fmean*sd(lidarData$LogRatio)
fvar_unscaled = gpParam$fvar*sd(lidarData$LogRatio)^2
plotGP(fmean_unscaled, fvar_unscaled, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
# b() c()
# BETTER ALTERNATIVE
sigmaN = 0.05
graphics.off()
par(mfrow=c(2,1))
for (length in list(1,5)){
gpParam = posteriorGP(scale(lidarData$Distance), scale(lidarData$LogRatio),
scale(lidarData$Distance), sigmaN/sd(lidarData$LogRatio)^2, kernelWrapper(sigmaF = 1, l = 1))
fmean_unscaled = mean(lidarData$LogRatio) + gpParam$fmean*sd(lidarData$LogRatio)
fvar_unscaled = gpParam$fvar*sd(lidarData$LogRatio)^2
plotGP(fmean_unscaled, fvar_unscaled, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
}
graphics.off()
par(mfrow=c(2,1))
for (length in list(1,5)){
gpParam = posteriorGP(scale(lidarData$Distance), scale(lidarData$LogRatio),
scale(lidarData$Distance), sigmaN/sd(lidarData$LogRatio)^2, kernelWrapper(sigmaF = 1, l = length))
fmean_unscaled = mean(lidarData$LogRatio) + gpParam$fmean*sd(lidarData$LogRatio)
fvar_unscaled = gpParam$fvar*sd(lidarData$LogRatio)^2
plotGP(fmean_unscaled, fvar_unscaled, lidarData$Distance, lidarData$Distance, lidarData$LogRatio, sigmaN)
}
source('O:/advML/Exam 231019/Assignment4.R')
plotGP(fmean_unscaled, fvar_unscaled, small.data$time, small.data$time, small.data$temp, sigmaNoise)
unscaled_polyFit <-
lm(small.data$temp ~  small.data$time + I(small.data$time ^ 2))
sigmaNoise_unscaled = sd(unscaled_polyFit$residuals)
plotGP(fmean_unscaled, fvar_unscaled, small.data$time, small.data$time, small.data$temp, sigmaNoise_unscaled)
optim(par = c(1,0.1),
fn = LM, X=scale(time),y=scale(temp),Xstar=scale(time),sigmaNoise=sigmaNoise,k=kernelWrap(sigmaF=20,l=0.2),
method="L-BFGS-B",
lower = c(.Machine$double.eps, .Machine$double.eps),
control=list(fnscale=-1))
optim(par = c(1,0.1),
fn = loglike, X=scale(time),y=scale(temp),Xstar=scale(time),sigmaNoise=sigmaNoise,k=kernelWrap(sigmaF=20,l=0.2),
method="L-BFGS-B",
lower = c(.Machine$double.eps, .Machine$double.eps),
control=list(fnscale=-1))
# Posterior of gaussian process
loglike = function (X, y, Xstar, sigmaNoise, k){
kstar = k(X,Xstar)
L = chol(k(X,X)+sigmaNoise^2*diag(length(X)))
L = t(L)
alpha = solve(t(L), solve(L,y))
fMean = t(kstar) %*% alpha
v = solve(L,kstar)
fVar = k(Xstar, Xstar)-t(v)%*%v
logMarginalLike = -0.5*t(y)%*%alpha-sum(sum(log(L)))-length(y)/2*log(2*pi)
return (logMarginalLike)
}
optim(par = c(1,0.1),
fn = loglike, X=scale(time),y=scale(temp),Xstar=scale(time),sigmaNoise=sigmaNoise,k=kernelWrap(sigmaF=20,l=0.2),
method="L-BFGS-B",
lower = c(.Machine$double.eps, .Machine$double.eps),
control=list(fnscale=-1))
help(optim)
# Posterior of gaussian process
loglike = function (sigmaF, l, X, y, Xstar, sigmaNoise){
k = kernelWrap(sigmaF, l)
kstar = k(X,Xstar)
L = chol(k(X,X)+sigmaNoise^2*diag(length(X)))
L = t(L)
alpha = solve(t(L), solve(L,y))
fMean = t(kstar) %*% alpha
v = solve(L,kstar)
fVar = k(Xstar, Xstar)-t(v)%*%v
logMarginalLike = -0.5*t(y)%*%alpha-sum(sum(log(L)))-length(y)/2*log(2*pi)
return (logMarginalLike)
}
optim(par = c(1,0.1),
fn = loglike,sigmaF=20,l=0.2, X=scale(time),y=scale(temp),Xstar=scale(time),sigmaNoise=sigmaNoise,
method="L-BFGS-B",
lower = c(.Machine$double.eps, .Machine$double.eps),
control=list(fnscale=-1))
optim(par = c(1,0.1),
fn = loglike, X=scale(time),y=scale(temp),Xstar=scale(time),sigmaNoise=sigmaNoise,
method="L-BFGS-B",
lower = c(.Machine$double.eps, .Machine$double.eps),
control=list(fnscale=-1))
optim(start = c(1,0.1),
fn = loglike, X=scale(time),y=scale(temp),Xstar=scale(time),sigmaNoise=sigmaNoise,
method="L-BFGS-B",
lower = c(.Machine$double.eps, .Machine$double.eps),
control=list(fnscale=-1))
optim(par = c(1,0.1),
fn = loglike, X=scale(small.data$time),y=scale(small.data$temp),Xstar=scale(small.data$time),sigmaNoise=sigmaNoise,
method="L-BFGS-B",
lower = c(.Machine$double.eps, .Machine$double.eps),
control=list(fnscale=-1))
optim(par = c(1,0.1),
fn = loglike, X=scale(small.data$time),y=scale(small.data$temp),Xstar=scale(small.data$time),sigmaNoise=sigmaNoise,
method="L-BFGS-B",
lower = c(.Machine$double.eps, .Machine$double.eps),
control=list(fnscale=-1))
# Posterior of gaussian process
loglike = function (sigmaF, l, X, y, Xstar, sigmaNoise){
print(sigmaF)
print(l)
print(x)
k = kernelWrap(sigmaF, l)
kstar = k(X,Xstar)
L = chol(k(X,X)+sigmaNoise^2*diag(length(X)))
L = t(L)
alpha = solve(t(L), solve(L,y))
fMean = t(kstar) %*% alpha
v = solve(L,kstar)
fVar = k(Xstar, Xstar)-t(v)%*%v
logMarginalLike = -0.5*t(y)%*%alpha-sum(sum(log(L)))-length(y)/2*log(2*pi)
return (logMarginalLike)
}
optim(par = c(1,0.1),
fn = loglike, X=scale(small.data$time),y=scale(small.data$temp),Xstar=scale(small.data$time),sigmaNoise=sigmaNoise,
method="L-BFGS-B",
lower = c(.Machine$double.eps, .Machine$double.eps),
control=list(fnscale=-1))
# Posterior of gaussian process
loglike = function (params, X, y, Xstar, sigmaNoise){
sigmaF = params[1]
l = params[2]
k = kernelWrap(sigmaF, l)
kstar = k(X,Xstar)
L = chol(k(X,X)+sigmaNoise^2*diag(length(X)))
L = t(L)
alpha = solve(t(L), solve(L,y))
fMean = t(kstar) %*% alpha
v = solve(L,kstar)
fVar = k(Xstar, Xstar)-t(v)%*%v
logMarginalLike = -0.5*t(y)%*%alpha-sum(sum(log(L)))-length(y)/2*log(2*pi)
return (logMarginalLike)
}
optim(par = c(1,0.1),
fn = loglike, X=scale(small.data$time),y=scale(small.data$temp),Xstar=scale(small.data$time),sigmaNoise=sigmaNoise,
method="L-BFGS-B",
lower = c(.Machine$double.eps, .Machine$double.eps),
control=list(fnscale=-1))
gpParam$logLike
# Posterior of gaussian process
loglike = function (params, X, y, Xstar, sigmaNoise){
sigmaF = params[1]
l = params[2]
k = kernelWrap(sigmaF, l)
kstar = k(X,Xstar)
L = chol(k(X,X)+sigmaNoise^2*diag(length(X)))
L = t(L)
alpha = solve(t(L), solve(L,y))
fMean = t(kstar) %*% alpha
v = solve(L,kstar)
fVar = k(Xstar, Xstar)-t(v)%*%v
logMarginalLike = -0.5*(t(y)%*%alpha)-sum(diag(L))-length(y)/2*log(2*pi)
return (logMarginalLike)
}
# Posterior of gaussian process
posteriorGP = function (X, y, Xstar, sigmaNoise, k){
kstar = k(X,Xstar)
L = chol(k(X,X)+sigmaNoise^2*diag(length(X)))
L = t(L)
alpha = solve(t(L), solve(L,y))
fMean = t(kstar) %*% alpha
v = solve(L,kstar)
fVar = k(Xstar, Xstar)-t(v)%*%v
logMarginalLike = -0.5*(t(y)%*%alpha)-sum(diag(L))-length(y)/2*log(2*pi)
return (list(fmean=fMean, fvar=fVar, logLike=logMarginalLike))
}
# Posterior of gaussian process
loglike = function (params, X, y, Xstar, sigmaNoise){
sigmaF = params[1]
l = params[2]
k = kernelWrap(sigmaF, l)
kstar = k(X,Xstar)
L = chol(k(X,X)+sigmaNoise^2*diag(length(X)))
L = t(L)
alpha = solve(t(L), solve(L,y))
fMean = t(kstar) %*% alpha
v = solve(L,kstar)
fVar = k(Xstar, Xstar)-t(v)%*%v
logMarginalLike = -0.5*(t(y)%*%alpha)-sum(diag(L))-length(y)/2*log(2*pi)
return (logMarginalLike)
}
gpParam = posteriorGP(scale(small.data$time), scale(small.data$temp), scale(small.data$time), sigmaNoise, kernelWrap(sigmaF=20,l=0.2))
gpParam$logLike
optim(par = c(1,0.1),
fn = loglike, X=scale(small.data$time),y=scale(small.data$temp),Xstar=scale(small.data$time),sigmaNoise=sigmaNoise,
method="L-BFGS-B",
lower = c(.Machine$double.eps, .Machine$double.eps),
control=list(fnscale=-1))
optimal = optim(par = c(1,0.1),
fn = loglike, X=scale(small.data$time),y=scale(small.data$temp),Xstar=scale(small.data$time),sigmaNoise=sigmaNoise,
method="L-BFGS-B",
lower = c(.Machine$double.eps, .Machine$double.eps),
control=list(fnscale=-1))
optimal
optimal$par
gpParam = posteriorGP(scale(small.data$time), scale(small.data$temp), scale(small.data$time), sigmaNoise, kernelWrap(sigmaF=optimal$par[1],l=optimal$par[2]))
fmean_unscaled = mean(small.data$temp) + gpParam$fmean*sd(small.data$temp)
fvar_unscaled = gpParam$fvar*sd(small.data$temp)^2
plotGP(fmean_unscaled, fvar_unscaled, small.data$time, small.data$time, small.data$temp, sigmaNoise_unscaled)
source('O:/advML/Exam 231019/Assignment4-2.R')
source('O:/advML/Exam 231019/Assignment4-2.R')
library(AtmRay)
library(kernlab)
# plots cov1, cov2 against target with contours given a trained GP modell GPfit
makeGridPlot = function(GPfit,
targetName,
cov1Name,
cov2Name,
data) {
cov1Col = which(names(data) == cov1Name)
cov2Col = which(names(data) == cov2Name)
targetCol = which(names(data) == targetName)
x1 <- seq(min(data$varWave), max(data$varWave), length = 100)
x2 <- seq(min(data$skewWave), max(data$skewWave), length = 100)
gridPoints <- meshgrid(x1, x2)
gridPoints <- cbind(c(gridPoints$x), c(gridPoints$y))
gridPoints <- data.frame(gridPoints)
names(gridPoints) <- c(names(data)[1], names(data)[2])
probPreds <- predict(GPfit, gridPoints, type = "probabilities")
contour(
x1,
x2,
matrix(probPreds[, 2], 100, byrow = TRUE),
20,
xlab = cov1Name,
ylab = cov2Name,
main = sprintf('Prob(%s) - 1:blue  0:red', targetName)
)
points(data[data[, targetCol] == "0", cov1Col], data[data[, targetCol] == "0", cov2Col], col =
"red")
points(data[data[, targetCol] == "1", cov1Col], data[data[, targetCol] == "1", cov2Col], col =
"blue")
}
#Prints accuracy and confusion tables given predictions and targets
printAccAndConf = function(label, preds, real) {
conf = table(preds, real)
acc = sum(diag(conf)) / sum(conf)
print(sprintf("%s Confusion table", label))
print(conf)
print(sprintf("%s Accuracy: %g", label, acc))
}
data <-
read.csv(
"https://github.com/STIMALiU/AdvMLCourse/raw/master/
GaussianProcess/Code/banknoteFraud.csv",
header = FALSE,
sep = ","
)
names(data) <-
c("varWave", "skewWave", "kurtWave", "entropyWave", "fraud")
data[, 5] <- as.factor(data[, 5])
set.seed(111)
trainIndex <- sample(1:dim(data)[1], size = 1000,
replace = FALSE)
train = data[trainIndex, ]
test = data[-trainIndex, ]
## Assignment 1
GPfit <- gausspr(fraud ~  varWave + skewWave +  kurtWave, data = train)
makeGridPlot(GPfit, "fraud", "varWave", "skewWave", train)
makeGridPlot(GPfit, "fraud", "varWave", "skewWave", "kurtWave", train)
makeGridPlot(GPfit, "fraud", "varWave", "skewWave", train)
library(AtmRay)
library(kernlab)
#Prints accuracy and confusion tables given predictions and targets
printAccAndConf = function(label, preds, real) {
conf = table(preds, real)
acc = sum(diag(conf)) / sum(conf)
print(sprintf("%s Confusion table", label))
print(conf)
print(sprintf("%s Accuracy: %g", label, acc))
}
data <-
read.csv(
"https://github.com/STIMALiU/AdvMLCourse/raw/master/
GaussianProcess/Code/banknoteFraud.csv",
header = FALSE,
sep = ","
)
names(data) <-
c("varWave", "skewWave", "kurtWave", "entropyWave", "fraud")
data[, 5] <- as.factor(data[, 5])
set.seed(111)
trainIndex <- sample(1:dim(data)[1], size = 1000,
replace = FALSE)
train = data[trainIndex, ]
test = data[-trainIndex, ]
## Assignment 1
GPfit <- gausspr(fraud ~  varWave + skewWave +  kurtWave, data = train)
# conf matrix
train_predict = predict(GPfit, train)
printAccAndConf("Train", train_predict, train$fraud)
## Assignment 2
test_predict = predict(GPfit, test)
printAccAndConf("Test", test_predict, test$fraud)
# Assignment 3
GPfitAll <- gausspr(fraud ~  ., data = train)
all_test_predict = predict(GPfitAll, test)
printAccAndConf("Test", all_test_predict, test$fraud)
makeGridPlot(GPfitAll, "fraud", "varWave", "skewWave", test)
printAccAndConf("Test", all_test_predict, test$fraud)
## Assignment 1
GPfit <- gausspr(fraud ~  ., data = train)
# Posterior of gaussian process
posteriorGP = function (X, y, Xstar, sigmaNoise, k){
kstar = k(X,Xstar)
L = chol(k(X,X)+sigmaNoise^2*diag(length(X)))
L = t(L)
alpha = solve(t(L), solve(L,y))
fMean = t(kstar) %*% alpha
v = solve(L,kstar)
fVar = k(Xstar, Xstar)-t(v)%*%v
logMarginalLike = -0.5*(t(y)%*%alpha)-sum(diag(L))-length(y)/2*log(2*pi)
return (list(fmean=fMean, fvar=fVar, logLike=logMarginalLike))
}
help("gausspr")
kernelWrap = function(sigmaF, l) {
expKernel <- function(x1, x2) {
n1 <- length(x1)
n2 <- length(x2)
K <- matrix(NA, n1, n2)
for (i in 1:n2) {
K[, i] <- sigmaF ^ 2 * exp(-0.5 * ((x1 - x2[i]) / l) ^ 2)
}
return(K)
}
class(expKernel) <- 'kernel'
return(expKernel)
}
help(gausspr)
testAcc = function(param, train, validation, kernelWrap){
GPfit <- gausspr(fraud ~  ., data = train, kpar(list(sigma=param)))
val_preds = predict(GPfit, validation)
return(getAcc(val_preds, validation$fraud))
}
optimal = optim(par = c(0.1),
fn = testAcc, train = train, validation = validation,
method="L-BFGS-B",
lower = c(.Machine$double.eps),
control=list(fnscale=-1))
source('O:/advML/Exam 231019/Assignment4-2.R')
source('O:/advML/Exam 231019/Assignment4-2.R')
#Prints accuracy and confusion tables given predictions and targets
printAccAndConf = function(label, preds, real) {
conf = table(preds, real)
acc = sum(diag(conf)) / sum(conf)
print(sprintf("%s Confusion table", label))
print(conf)
print(sprintf("%s Accuracy: %g", label, acc))
}
optimal$par
GPfitAll <- gausspr(fraud ~  ., data = train, kpar=optimal$par)
all_test_predict = predict(GPfitAll, validation)
printAccAndConf("Test", all_test_predict, validation$fraud)
source('O:/advML/Exam 231019/Assignment4-2.R')
source('O:/advML/Exam 231019/Assignment4-2.R')
source('O:/advML/Exam 231019/Assignment4-2.R')
source('O:/advML/Exam 231019/Assignment4-2.R')
source('O:/advML/Exam 231019/Assignment4-2.R')
source('O:/advML/Exam 231019/Assignment4-2.R')
source('O:/advML/Exam 231019/Assignment4-2.R')
source('O:/advML/Exam 231019/Assignment4-2.R')
source('O:/advML/Exam 231019/Assignment4-2.R')
best_par = 0.1
best_acc = 0
pars = c(0, 10, by=0.5)
for (par in pars){
currAcc = testAcc(par, train, validation)
if(currAcc>best_acc){
best_par = par
best_acc = currAcc
}
}
best_par = 0.1
best_acc = 0
pars = seq(0, 10, by=0.5)
for (par in pars){
currAcc = testAcc(par, train, validation)
if(currAcc>best_acc){
best_par = par
best_acc = currAcc
}
}
print(sprintf("Best sigma: %g  Accuracy: %g", best_par, best_acc))
GPfitAll <- gausspr(fraud ~  ., data = train, kernel="rbfdot", kpar=list(sigma=best_par))
all_test_predict = predict(GPfitAll, validation)
printAccAndConf("Test", all_test_predict, validation$fraud)
